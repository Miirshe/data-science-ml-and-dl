{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360d4eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facebook-scraperNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for facebook-scraper from https://files.pythonhosted.org/packages/14/3b/b8d70369a4ed461bb19b2547066ceaf3659ecf1bf5f27f8727225309f75f/facebook_scraper-0.2.59-py3-none-any.whl.metadata\n",
      "  Downloading facebook_scraper-0.2.59-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dateparser<2.0.0,>=1.0.0 (from facebook-scraper)\n",
      "  Obtaining dependency information for dateparser<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/a4/29/db12aa4dda81580be1999824a689bd52aa40061fc12c9ccdc3feab5ea718/dateparser-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting demjson3<4.0.0,>=3.0.5 (from facebook-scraper)\n",
      "  Downloading demjson3-3.0.6.tar.gz (131 kB)\n",
      "     ---------------------------------------- 0.0/131.5 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 30.7/131.5 kB 640.0 kB/s eta 0:00:01\n",
      "     ----------- ------------------------- 41.0/131.5 kB 653.6 kB/s eta 0:00:01\n",
      "     ----------------- ------------------- 61.4/131.5 kB 465.5 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 112.6/131.5 kB 652.2 kB/s eta 0:00:01\n",
      "     ------------------------------------ 131.5/131.5 kB 644.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting requests-html<0.11.0,>=0.10.0 (from facebook-scraper)\n",
      "  Obtaining dependency information for requests-html<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook-scraper) (2.8.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook-scraper) (2023.3.post1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook-scraper) (2022.7.9)\n",
      "Collecting tzlocal (from dateparser<2.0.0,>=1.0.0->facebook-scraper)\n",
      "  Obtaining dependency information for tzlocal from https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl.metadata\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook-scraper) (2.31.0)\n",
      "Collecting pyquery (from requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for pyquery from https://files.pythonhosted.org/packages/36/b7/f7ccf9e52e2817e1265d3719c600fa4ef33c07de4d5ef0ced3f43ab1cef2/pyquery-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fake-useragent (from requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for fake-useragent from https://files.pythonhosted.org/packages/33/c9/ff44922639b8827dbc86d463d870dabfc19d1567d8a6427dcb2289d83fd8/fake_useragent-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parse (from requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for parse from https://files.pythonhosted.org/packages/ce/f0/30fe1494f1910ad3ea40639b13ac48cdb16a8600e8861cbfc2c560661ddf/parse-1.20.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading parse-1.20.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: bs4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook-scraper) (0.0.2)\n",
      "Requirement already satisfied: w3lib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook-scraper) (1.21.0)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for pyppeteer>=0.0.14 from https://files.pythonhosted.org/packages/3d/ee/fb2757a38025421fd3844a0ed0a230b78c9c04a66355024436cf3005a70c/pyppeteer-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (2024.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (6.0.0)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for pyee<12.0.0,>=11.0.0 from https://files.pythonhosted.org/packages/16/cc/5cea8a0a0d3deb90b5a0d39ad1a6a1ccaa40a9ea86d793eb8a49d32a6ed0/pyee-11.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (4.65.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (1.26.16)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for websockets<11.0,>=10.0 from https://files.pythonhosted.org/packages/27/bb/6327e8c7d4dd7d5b450b409a461be278968ce05c54da13da581ac87661db/websockets-10.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading websockets-10.4-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook-scraper) (4.12.2)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook-scraper) (4.9.3)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html<0.11.0,>=0.10.0->facebook-scraper)\n",
      "  Obtaining dependency information for cssselect>=1.2.0 from https://files.pythonhosted.org/packages/06/a9/2da08717a6862c48f1d61ef957a7bba171e7eefa6c0aa0ceb96a140c2a6b/cssselect-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil->dateparser<2.0.0,>=1.0.0->facebook-scraper) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook-scraper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook-scraper) (3.4)\n",
      "Requirement already satisfied: tzdata in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal->dateparser<2.0.0,>=1.0.0->facebook-scraper) (2023.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook-scraper) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests-html<0.11.0,>=0.10.0->facebook-scraper) (2.4)\n",
      "Downloading facebook_scraper-0.2.59-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 61.4/295.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 143.4/295.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 174.1/295.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 286.7/295.0 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 295.0/295.0 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.9 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 61.4/82.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 82.9/82.9 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading websockets-10.4-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.4 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 61.4/101.4 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.4/101.4 kB 1.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: demjson3\n",
      "  Building wheel for demjson3 (setup.py): started\n",
      "  Building wheel for demjson3 (setup.py): finished with status 'done'\n",
      "  Created wheel for demjson3: filename=demjson3-3.0.6-py3-none-any.whl size=75333 sha256=052aad68ebe3b83cff3acf2638f142ccaf48593ffb780aaaacff696a8f07f425\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\3b\\9d\\d5\\e8cbb4d529989f6d3f347fe914559ea4f66715bf299763af1c\n",
      "Successfully built demjson3\n",
      "Installing collected packages: parse, fake-useragent, demjson3, websockets, tzlocal, pyee, cssselect, pyquery, pyppeteer, dateparser, requests-html, facebook-scraper\n",
      "  Attempting uninstall: cssselect\n",
      "    Found existing installation: cssselect 1.1.0\n",
      "    Uninstalling cssselect-1.1.0:\n",
      "      Successfully uninstalled cssselect-1.1.0\n",
      "Successfully installed cssselect-1.2.0 dateparser-1.2.0 demjson3-3.0.6 facebook-scraper-0.2.59 fake-useragent-1.4.0 parse-1.20.1 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests-html-0.10.0 tzlocal-5.2 websockets-10.4\n"
     ]
    }
   ],
   "source": [
    "pip install facebook-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23414d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'comments_full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# extract the comments part\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m comments \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments_full\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# process comments as you want...\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments:\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# e.g. ...print them\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments_full'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download comments for a public Facebook post.\n",
    "\"\"\"\n",
    "\n",
    "import facebook_scraper as fs\n",
    "\n",
    "# get POST_ID from the URL of the post which can have the following structure:\n",
    "# https://www.facebook.com/USER/posts/POST_ID\n",
    "# https://www.facebook.com/groups/GROUP_ID/posts/POST_ID\n",
    "POST_ID = \"https://www.facebook.com/watch/?v=954359099458540&__cft__[0]=AZVyoePQU2ejenNo1vfVECvo0GRN4Z9L0phdryZuxs5jPSMFsGi-lHLdTE5YU8Hyvgp521k6F_6cr9HY2RMdAhUbyMTUJZaWDLcK6LqKkw_LaZ5kFFiddvnVaZgSuL9bjlVbrWwmwndp6kwIMkcRPOWOVL_rDLmhZBrdI-Xot6pm7e1mCDNYbz9b6A5eOmVUgKY&__tn__=%2CO%2CP-R\"\n",
    "\n",
    "# number of comments to download -- set this to True to download all comments\n",
    "MAX_COMMENTS = 100\n",
    "\n",
    "# get the post (this gives a generator)\n",
    "gen = fs.get_posts(\n",
    "    post_urls=[POST_ID],\n",
    "    options={\"comments\": MAX_COMMENTS, \"progress\": True}\n",
    ")\n",
    "\n",
    "# take 1st element of the generator which is the post we requested\n",
    "post = next(gen)\n",
    "\n",
    "# extract the comments part\n",
    "comments = post['comments_full']\n",
    "\n",
    "# process comments as you want...\n",
    "for comment in comments:\n",
    "\n",
    "    # e.g. ...print them\n",
    "    print(comment)\n",
    "\n",
    "    # e.g. ...get the replies for them\n",
    "    for reply in comment['replies']:\n",
    "        print(' ', reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e0cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
